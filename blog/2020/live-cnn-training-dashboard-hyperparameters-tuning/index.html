<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <h4><a href="https://towardsdatascience.com/tagged/hands-on-tutorials" rel="external nofollow noopener" target="_blank">Hands-on Tutorials</a></h4> <h3>Table of contents</h3> <ol> <li><strong>Why we need to build a Live CNN Training Dashboard?</strong></li> <li><strong>Introduction</strong></li> <li><strong>Prerequisites</strong></li> <li><strong>System description</strong></li> <li><strong>How to create an environment and start training?</strong></li> <li><strong>Conclusion</strong></li> <li><strong>References</strong></li> </ol> <h3>Why we need to build a Live CNN Training Dashboard?</h3> <p>When I studied in mathematical lyceum, my teacher taught me that the best way to understand something is to visualize it. For example, we had a wooden board, plasticine, and metal wire to be able to visualize stereometry problems. It helped a lot to develop visual thinking and skills in solving challenging tasks.</p> <p>I truly believe that real data scientists should understand algorithms and have a feeling on how to improve it if something works not fine. Especially in the area of deep learning. In my mind, the best way to develop these skills is to see how the model is trained, what happens when you change hyperparameters. This is the reason why I want to share how to build a simple dashboard for CNN live training with the opportunity to tune a few hyperparameters online.</p> <p>There is common knowledge that if we choose too big learning rate, we will see how our loss function explodes (our model will not converge); if we choose too small learning rate, the training process can last too long. What about dropout? There is an opinion that dropout reduces overfitting. I get to check everything myself even if I believe, because to know and to believe are different things.</p> <p>Below is the short demo of my dashboard. Red dots on loss function &amp; accuracy plots represent the training dataset, blue dots represent the test dataset.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/866/1*HhRidOhxiPrvrThYqqz3Pg.gif"><figcaption>Image by the author</figcaption></figure> <h3>Introduction</h3> <p>Dashboard displays the following statistics:</p> <ul> <li>loss function value in time;</li> <li>accuracy in time;</li> <li>distribution of activation maps values for the last step;</li> <li>history of hyperparameters changes (table);</li> </ul> <p>For this task, I am using AlexNet architecture to classify images on 10 classes: Alaskan malamute, baboon, echidna, giant panda, hippo, king penguin, llama, otter, red panda, and wombat. Images are downloaded from the ImageNet. I will not go into details in this post, but you can explore file <strong>get_dataset.py</strong>. During training, the following parameters can be tweaked:</p> <ul> <li>optimizer;<br>This parameter determines the algorithm we use to optimize our model. I use only Adam and SGD with Nesterov momentum. If you want to understand the optimization technique more, I encourage you to watch a video from Stanford <a href="https://www.youtube.com/watch?v=_JB0AO7QxSA" rel="external nofollow noopener" target="_blank">here</a>. There are many fantastic details about optimization.</li> <li>learning rate;<br>This parameter determines how fast we are moving down the slope when we are updating weights. For basic gradient descent formula for weights updates look like this: w := w — lr * dw.</li> <li>weight decay;<br>For our case it is simply L2 regularization: R(W) = SUM(W * W). It is considered that weight decay does not make a lot of sense in the context of CNN, but you can see it yourself how it works live. You can read some description of L1 and L2 regularization techniques <a href="https://towardsdatascience.com/l1-and-l2-regularization-methods-ce25e7fc831c" rel="external nofollow noopener" target="_blank">here</a>.</li> <li>dropout;<br>Common regularization strategy for neural network. The idea is randomly set some neurons to zero on each training step. The hyperparameter is the probability to drop each neuron. Common value is 0.5 (50%). We can choose any integer value from 20 to 80. (in %) More details can be watched in the same video that I shared for optimizer.</li> </ul> <p>Script can be easily changed to add additional functionality.</p> <h3>Prerequisites</h3> <p>I assume that you understand what is CNN and have basic knowledge of the following:</p> <ul> <li>PostgreSQL (to store real-time data);</li> <li>Dash (to build dashboard, <a href="https://plotly.com/dash/" rel="external nofollow noopener" target="_blank">https://plotly.com/dash/</a>);</li> <li>PyTorch (to build CNN models);</li> </ul> <h3>System description</h3> <p>There are four main parts of the system: <em>dataset, model, database, and dashboard/UI</em>. These parts interact with each other to successfully run the system. Firstly I will describe each of these parts and after that, I will give a short description of how they interact with each other.</p> <h4>Dataset</h4> <p>For this exercise, I use a dataset from the ImageNet that contains the following ten classes: <em>Alaskan malamute, baboon, echidna, giant panda, hippo, king penguin, llama, otter, red panda, and wombat. </em>To download all images from ImageNet, I can run python board.py from the following location: ../cnn_live_training.</p> <p>Firstly, I have to find classes ids and save them to some variable:</p> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/9f15dc13a20215b8bb39c30e5a55a92b/href" rel="external nofollow noopener" target="_blank">https://medium.com/media/9f15dc13a20215b8bb39c30e5a55a92b/href</a></iframe> <p>The ImageNet stores URLs to images. Some URLs/images might not exist anymore. To get these URLs based on class id, I use the following function:</p> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/e2e0b5d5a9bc2bf913270f868e053ede/href" rel="external nofollow noopener" target="_blank">https://medium.com/media/e2e0b5d5a9bc2bf913270f868e053ede/href</a></iframe> <p>To download all images I use a loop where I download image by image. Below is the function to download image by URL:</p> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/5e40c6ec93877779ada08f4bab23aae6/href" rel="external nofollow noopener" target="_blank">https://medium.com/media/5e40c6ec93877779ada08f4bab23aae6/href</a></iframe> <p>The full version of the code can be seen in the file <strong>get_dataset.py</strong>. You can easily change these classes to other classes or you can even change the ImageNet to your custom dataset.</p> <h4>Model</h4> <p>For the training, I am using by default the AlexNet architecture with Adam or SGD with Nesterov momentum optimizer. Optionally, the VGG16 can be chosen. Models can be imported either from the file <strong>models.py</strong> or from torchvision.models. The second option has the opportunity to use pre-trained weights. Dataset preparation happens in the file <strong>data_preparation.py</strong>. The training process happens in the file <strong>train.py</strong>.</p> <p>I don’t have the goal to explain in this article how to build a pipeline for training CNN that is why I am not going into detail in this part. But I am happy to recommend the amazing course CS231n from Stanford and particularly HW2(Q4), where you can learn step by step how to build this pipeline. This homework can be found <a href="https://cs231n.github.io/assignments2020/assignment2/" rel="external nofollow noopener" target="_blank">here</a>.</p> <h4>Database</h4> <p>Before running the system, we have to create <em>dl_playground</em> DB in PostgreSQL with the schema <em>cnn_live_training</em> that contains three following tables: <em>parameters, statistics, activations</em>.</p> <p><strong>parameters</strong><br>This table contains <em>only one row</em> with current parameters for the training CNN model. When we change any parameters in our dashboard (file <strong>board.py</strong>), this data will be updated in the <em>parameters</em> SQL table. The table contains the following columns:</p> <ul> <li>optimizer;<br>Text data type. Can have two values: ‘Adam’ and ‘SGD+Nesterov’.</li> <li>learning_rate;<br>Double data type. The values are between 0 and 1 with the 0.00005 step.</li> <li>weight_decay;<br>Double data type. The values are between 0 and 1 with the 0.05 step.</li> <li>dropout;<br>Integer data type. The values are between 20 and 80. (It is assumed that the values are in %.)</li> <li>dt_updates;<br>Timestamp data type. Indicates date and time when data was modified.</li> <li>stop_train;<br>Boolean data type. Indicates if we have to stop training.</li> </ul> <p><strong>statistics<br></strong> This table contains statistics of the training process. Data is updated every --n-print step. The table contains the following columns:</p> <ul> <li>dt_started;<br>Timestamp data type. Indicates when current training was started.</li> <li>model_name;<br>Text data type. In this case, it can be only ‘MyAlexNet’.</li> <li>epoch;<br>Integer data type. Indicates the number of training epochs.</li> <li>step;<br>Integer data type. Indicates the number of training steps.</li> <li>optimizer;<br>Text data type. Can have two values: ‘Adam’ and ‘SGD+Nesterov’.</li> <li>learning_rate;<br>Double data type. The values are between 0 and 1 with the 0.00005 step.</li> <li>weight_decay;<br>Double data type. The values are between 0 and 1 with the 0.05 step.</li> <li>dropout;<br>Integer data type. The values are between 20 and 80.</li> <li>dt;<br>Timestamp data type. Indicates date and time when data was modified.</li> <li>train_loss;<br>Double data type. The value of loss function for the training dataset on the last step.</li> <li>train_accuracy;<br>Double data type. The value of accuracy for the training dataset on the last step.</li> <li>validate_loss;<br>Double data type. The value of loss function for the validation dataset on the last step.</li> <li>validate_accuracy;<br>Double data type. The value of accuracy for the validation dataset on the last step.</li> </ul> <p><strong>activations</strong><br>This table contains the current distribution of weights in activation maps for all convolutional and fully connected layers. The table contains the following columns:</p> <ul> <li>nn_part;<br>Text data type. Can be either ‘features’ or ‘classifier’.</li> <li>layer_type;<br>Text data type. Can be either ‘conv’ or ‘fc’.</li> <li>number;<br>Integer data type. Indicates the layer number in a ‘nn’ part.</li> <li>weights;<br>Double[] data type. Indicates average values of weights in bins.</li> <li>num_weights;<br>Integer[] data type. Indicates numbers of values in bins.</li> </ul> <h4>Dashboard/UI</h4> <p>The dashboard consists of three main blocks: <em>control panel, loss function &amp; accuracy, and activation maps (distribution)</em>. These blocks are built using dash containers.</p> <p><strong>Control panel</strong> contains filters of parameters and “submit parameters” button that can be used to send chosen parameters to described above table “parameters”.<br>There are four filters: optimizer, learning rate, weight decay, and dropout.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*gO3qCjmZ2W_t53D2BY5U9g.png"><figcaption>Image by the author</figcaption></figure> <p>Below is the script, how to create an optimizer filter (other filters are similar):</p> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/4f8d477162beffe5461cdbbcc80f0906/href" rel="external nofollow noopener" target="_blank">https://medium.com/media/4f8d477162beffe5461cdbbcc80f0906/href</a></iframe> <p>After that I create a container that contains all four filters:</p> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/664f7649c8dde620e428b38602be1f62/href" rel="external nofollow noopener" target="_blank">https://medium.com/media/664f7649c8dde620e428b38602be1f62/href</a></iframe> <p>How to create other parts of the control panel can be found in the file <strong>board.py</strong>.</p> <p><strong>Loss function &amp; Accuracy</strong> contains a table with the history of used parameters and two plots with train/test loss function and accuracy values in time. Data is updated every one second (time interval can be changed) automatically.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*pnOp9JjL1Si19I9VCmsd-Q.png"><figcaption>Image by the author</figcaption></figure> <p>Below is the script on how to create a table and button to stop training in the dashboard (I replaced real styles with short names for reading convenience):</p> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/3789925ae6f251b225c7c20a2732e11f/href" rel="external nofollow noopener" target="_blank">https://medium.com/media/3789925ae6f251b225c7c20a2732e11f/href</a></iframe> <p>Script to create plot template can be seen below:</p> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/7297eb93fdf91a4436782acec545f1d1/href" rel="external nofollow noopener" target="_blank">https://medium.com/media/7297eb93fdf91a4436782acec545f1d1/href</a></iframe> <p>Values are uploaded dynamically from PostgreSQL using callbacks (I provide only template for reading convenience):</p> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/96ca5ddf33d265257bd1131dc18c5246/href" rel="external nofollow noopener" target="_blank">https://medium.com/media/96ca5ddf33d265257bd1131dc18c5246/href</a></iframe> <p>I need to use a callback here because I want to update the plot and the table every 1 second. So, I have to use this variable as an input.</p> <p><strong>Activation maps (distribution)</strong> contains plots with distribution of activation map for each layer for the last step. Data is updated every one second (time interval can be changed) automatically.</p> <p>The activations of the first two layers look similar to a normal distribution with the mean value in 0. The reason for this is for the first two layers we apply normalization. To understand more, I encourage you to watch a lecture from Stanford <a href="https://www.youtube.com/watch?v=wEoyxE0GP2M" rel="external nofollow noopener" target="_blank">here</a>.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*Hp19LuAebQOoa7F8wZL9dQ.png"><figcaption>Image by the author</figcaption></figure> <p>Below is the script to create a container with the plots. It is similar to the previous container with loss function and accuracy plots:</p> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/6cc47a3ce1631f15e01eef05b1e11308/href" rel="external nofollow noopener" target="_blank">https://medium.com/media/6cc47a3ce1631f15e01eef05b1e11308/href</a></iframe> <p>The callback for the activation maps is similar to the “loss function &amp; accuracy”:</p> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/bd88a63b7ba7f0cc176093907b5265cd/href" rel="external nofollow noopener" target="_blank">https://medium.com/media/bd88a63b7ba7f0cc176093907b5265cd/href</a></iframe> <h4>How everything works</h4> <p>It’s time to wrap everything up. To recall back, my goal is to train CNN live and being able to control this process by changing hyperparameters. So how does it happen? I have a dashboard where we can see the progress of the CNN training and where we have some filters that we can choose and activate by pushing the button “Submit parameters”.</p> <p>What happens after that? All these parameters are sent to the table <em>parameters</em> in my database in PostgreSQL, using callback in the file <strong>board.py</strong> and function <em>update_params</em>:</p> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/3167abb99f196edc04396152c1b451bf/href" rel="external nofollow noopener" target="_blank">https://medium.com/media/3167abb99f196edc04396152c1b451bf/href</a></iframe> <p>At the same time, the script <strong>train.py</strong> connects to a database at the end of each training step, seeking to update the optimizer if parameters get updated:</p> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/7ed8b471a893e37137e9db49c348ab03/href" rel="external nofollow noopener" target="_blank">https://medium.com/media/7ed8b471a893e37137e9db49c348ab03/href</a></iframe> <p>Every <em>n_step</em> step data from training is saved to <em>statistics</em> and <em>activations</em> tables in database in PostgreSQL:</p> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/8a5190d919b9f9d5182aca2b93e1140a/href" rel="external nofollow noopener" target="_blank">https://medium.com/media/8a5190d919b9f9d5182aca2b93e1140a/href</a></iframe> <p>And this data simultaneously displayed in the dashboard because the script <strong>board.py</strong> every 1 sec. connects to the same tables:</p> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/d86dbc3de1f22ea60d0dd7fd5a9d4c88/href" rel="external nofollow noopener" target="_blank">https://medium.com/media/d86dbc3de1f22ea60d0dd7fd5a9d4c88/href</a></iframe> <p>All parameters are displayed in the table by extracting this information from the table :</p> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/d8ea4b68cdc1c63bf63ebfa0aeac795b/href" rel="external nofollow noopener" target="_blank">https://medium.com/media/d8ea4b68cdc1c63bf63ebfa0aeac795b/href</a></iframe> <p>If we want to stop training beforehand, we can push the button “Stop Training” below the table. After pushing the button, the callback will change the variable <em>stop_train</em> from <em>False</em> to <em>True</em> in the <em>parameters</em> table in my database:</p> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/cc7ed36586b8e1730acef94864e944a0/href" rel="external nofollow noopener" target="_blank">https://medium.com/media/cc7ed36586b8e1730acef94864e944a0/href</a></iframe> <p>At the same time, the script <strong>train.py</strong> check this parameter every training step and if it is <em>True</em>, training will be interrupted.</p> <p>Without practical recommendations on what parameters to use to start training, this post will not be complete. If you want to see that everything works, but don’t have time for experiments, you can start from the following parameters:</p> <ul> <li>optimizer: Adam;</li> <li>learning rate: 0.0003;</li> <li>weight decay: 0;</li> <li>dropout: 50%;</li> </ul> <p>If you want to see how the model explodes, just increase the learning rate to 0.01. Good luck with your experiments.</p> <h3>How to create an environment and start training?</h3> <h4>Virtual environment setting up</h4> <p>I will give a short description for Ubuntu, using a virtual environment (<em>venv</em>).</p> <ol> <li>Install Python 3.8: sudo apt install python3.8-minimal</li> <li>Install virtual environment with Python 3.8: sudo apt-get install python3.8-venv</li> <li>Create virtual environment: run from cnn_live_training folder: python3.8 -m venv venv</li> <li>Activate environment: source venv/bin/activate</li> <li>Install required packages in the virtual environment: <br>pip install -r requirements.txt</li> </ol> <h4>Collect dataset</h4> <p>Run from the ../cnn_live_training command python get_dataset.py</p> <h4>Start training</h4> <p>Run from the ../cnn_live_training folder two following commands</p> <pre>python board.py<br>python train.py</pre> <h3>Conclusion</h3> <p>In this story, I wanted to share my idea on how to nurture the feeling of training CNN. From one side, the idea is simple: build a training pipeline, create a dashboard and connect them using a database. But there are many annoying details that not possible to put in one small story. All script and additional details can be found in my <a href="https://github.com/atimashov/cnn_live_training" rel="external nofollow noopener" target="_blank">git repository</a>.</p> <p>If this post makes someone interested and give additional knowledge, I will become slightly happier because it means that I reached my goal. I will appreciate any comments, constructive criticism, or questions, feel free to leave your feedback below or you can reach me via <a href="https://www.linkedin.com/in/alexander-timashov/" rel="external nofollow noopener" target="_blank">LinkedIn</a>.</p> <h3>References</h3> <p>[1] L. Fei-Fei, R. Krishna and D. Xu, <a href="http://cs231n.stanford.edu/" rel="external nofollow noopener" target="_blank">CS231n: Convolutional Neural Networks for Visual Recognition</a> (2020), Stanford University</p> <p>[2] A. Krizhevsky, I. Sutskever and G. E. Hinton, <a href="https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf" rel="external nofollow noopener" target="_blank">ImageNet Classification with Deep Convolutional Neural Networks</a> (2012), NeurIPS 2012</p> <p>[3] A. Nagpal, <a href="https://towardsdatascience.com/l1-and-l2-regularization-methods-ce25e7fc831c" rel="external nofollow noopener" target="_blank">L1 and L2 Regularization Methods</a> (2017), Towards Data Science</p> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=6b3382d9e44f" width="1" height="1" alt="">&lt;hr&gt;&lt;p&gt;<a href="https://medium.com/data-science/live-cnn-training-dashboard-hyperparameters-tuning-6b3382d9e44f" rel="external nofollow noopener" target="_blank">Live CNN Training Dashboard: Hyperparameters Tuning</a> was originally published in <a href="https://medium.com/data-science" rel="external nofollow noopener" target="_blank">TDS Archive</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.&lt;/p&gt;</p> </body></html>