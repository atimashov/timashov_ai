<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> How Computers Store Data in Memory: Brief Intro | Aleksandr Timashov </title> <meta name="author" content="Aleksandr Timashov"> <meta name="description" content="fp32, fp16, and more"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://timashov.ai/blog/2025/data-in-memory/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> <link defer rel="stylesheet" href="https://cdn.jsdelivr.net/npm/img-comparison-slider@8.0.6/dist/styles.min.css" integrity="sha256-3qTIuuUWIFnnU3LpQMjqiXc0p09rvd0dmj+WkpQXSR8=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://cdn.jsdelivr.net/npm/swiper@11.0.5/swiper-bundle.min.css" integrity="sha256-yUoNxsvX+Vo8Trj3lZ/Y5ZBf8HlBFsB6Xwm7rH75/9E=" crossorigin="anonymous"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Aleksandr Timashov </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">people </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/books/">bookshelf</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">How Computers Store Data in Memory: Brief Intro</h1> <p class="post-meta"> Created on April 26, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/pre-dl"> <i class="fa-solid fa-hashtag fa-sm"></i> pre-dl,</a>   <a href="/blog/tag/lecture-1"> <i class="fa-solid fa-hashtag fa-sm"></i> lecture-1</a>   ·   <a href="/blog/category/cs336"> <i class="fa-solid fa-tag fa-sm"></i> cs336</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <h2 id="introduction">Introduction</h2> <p>When <strong>we communicate</strong> with each other, we use complex <strong>natural languages</strong> like English, Portuguese, or Russian. The language we use depends on our location or the community around us. When we see something, we perceive information visually through our eyes and brain. And when we count numbers, most people are familiar with one system — the <strong>decimal system</strong>, where each position can be represented by one of 10 digits: <code class="language-plaintext highlighter-rouge">0, 1, 2, ..., 9</code>. So, at least three independent ways exist to perceive and exchange information.<br> <strong>Computers</strong>, however, operate very differently — and in some sense, much more simply. They do not have a native natural language or vision system at their core. Instead, they use only the <strong>binary system</strong>, composed of <code class="language-plaintext highlighter-rouge">0</code> and <code class="language-plaintext highlighter-rouge">1</code>. Each “box” of information can contain either a 0 or a 1, and this unit is called a <strong>bit</strong>. Historically, 8 bits make up a <strong>byte</strong>.</p> <p><img src="/assets/img/bits_bytes.png" alt="Img.1: Explanation of Bits and Bytes" style="width:100%;"></p> <p>Higher-level constructs, such as <strong>Natural Language Models</strong> (<em>LLaMA, ChatGPT, Grok, etc.</em>) and <strong>Vision Systems</strong> (<em>YOLO, Faster R-CNN, Stable Diffusion, etc.</em>), are built on top of this fundamental binary representation.</p> <p>Understanding how computers “speak” at the basic level is critical for building intuition in Deep Learning. In this post, I learn how computers represent and store information, how it connects to data types, and why these foundations matter when designing and optimizing AI models.</p> <hr> <h2 id="decimal-vs-binary">Decimal vs Binary</h2> <p>The <strong>decimal system</strong> is the numeral system we use in daily life. Each digit can take one of <em>10</em> different values: <code class="language-plaintext highlighter-rouge">0, 1, 2, ..., 9</code>, ordered naturally from smallest to largest. To construct numbers, we use powers of <em>10</em>: when increasing past <em>9</em>, we reset the digit to <em>0</em> and add <em>1</em> to the next higher place value. The <strong>binary system</strong> works similarly — but instead of <em>10</em> possible values, each digit (bit) can only be <code class="language-plaintext highlighter-rouge">0</code> or <code class="language-plaintext highlighter-rouge">1</code>. Here, the base is <em>2</em>, and each digit represents a power of <em>2</em>.</p> <p><img src="/assets/img/nums_seq.png" alt="Img.2: Sequence of numbers in Decimal and Binary systems" style="width:100%;"></p> <p>Fractional numbers follow the same idea: each digit after the floating point represents a negative power of the base - <em>10</em> for decimal numbers, and <em>2</em> for binary numbers. The algorithm for <strong>converting a fractional number from decimal to binary</strong> is iterative and slightly different for the integer and fractional parts:</p> <ul> <li>For the <strong>integer part</strong>, divide the number by <em>2</em>, record the remainder (<em>0</em> or <em>1</em>), and continue dividing the quotient by <em>2</em> <strong>until</strong> it becomes <em>0</em>.</li> <li>For the <strong>fractional part</strong>, multiply the fraction by <em>2</em>, record the integer part (<em>0</em> or <em>1</em>), and repeat the process with the remaining fractional part. The process <strong>stops when</strong> the fraction becomes 0 or when the desired precision is reached.</li> </ul> <p>Below is the step-by-step calculation for the number <code class="language-plaintext highlighter-rouge">13.875</code>:</p> <p><img src="/assets/img/binary_repr.png" alt="Img.3: Representation of fractional numbers in Decimal and Binary systems" style="width:100%;"></p> <p>We’re used to the decimal system; however, the binary system follows the exact same logic — just with <em>2</em> symbols instead of <em>10</em>. Inside a computer, tiny transistors act as switches that can be either ON or OFF, determined by voltage levels. It’s much easier and more reliable to distinguish just two states — high vs. low voltage — than to detect multiple. This simplicity and robustness is <strong>why all information in computers is stored in binary</strong>.</p> <h2 id="main-data-types">Main Data Types</h2> <p>At the core of computing, we work with a few basic types:</p> <ul> <li> <strong>Integer (<code class="language-plaintext highlighter-rouge">int</code>)</strong>: Whole numbers like <code class="language-plaintext highlighter-rouge">-17</code>, <code class="language-plaintext highlighter-rouge">0</code>, <code class="language-plaintext highlighter-rouge">256</code>, etc.</li> <li> <strong>Floating-point (<code class="language-plaintext highlighter-rouge">float</code>)</strong>: Numbers with decimals, like <code class="language-plaintext highlighter-rouge">3.1415</code> or <code class="language-plaintext highlighter-rouge">-0.00127</code>.</li> <li> <strong>Boolean (<code class="language-plaintext highlighter-rouge">bool</code>)</strong>: <code class="language-plaintext highlighter-rouge">True</code> or <code class="language-plaintext highlighter-rouge">False</code>, used in logical decisions.</li> <li> <strong>Character (<code class="language-plaintext highlighter-rouge">char</code>)</strong>: Single characters like <code class="language-plaintext highlighter-rouge">'a'</code>, <code class="language-plaintext highlighter-rouge">'Z'</code>, <code class="language-plaintext highlighter-rouge">'Я'</code>, <code class="language-plaintext highlighter-rouge">'+'</code>.</li> <li> <strong>String (<code class="language-plaintext highlighter-rouge">str</code>)</strong>: Sequences of characters like <code class="language-plaintext highlighter-rouge">"Capybara likes cuddling"</code>.</li> </ul> <p>Each type has a pre-allocated size that depends on the programming language and implementation details. For example:</p> <ul> <li> <code class="language-plaintext highlighter-rouge">int8</code> (8-bit integer) has a size of <em>1 byte</em> and can represent values between <code class="language-plaintext highlighter-rouge">-128</code> (<code class="language-plaintext highlighter-rouge">-2^7</code>) and <code class="language-plaintext highlighter-rouge">127</code> (<code class="language-plaintext highlighter-rouge">2^7 - 1</code>).</li> <li>A regular <code class="language-plaintext highlighter-rouge">int</code> in Python has a size of <em>28 bytes</em> — which may seem surprisingly large. This is because Python integers include significant metadata (type, reference counts, etc.) and allocate memory dynamically.</li> </ul> <p>One can check the size of an object <code class="language-plaintext highlighter-rouge">x</code> in Python with <code class="language-plaintext highlighter-rouge">sys.getsizeof(x)</code>. However, it measures the full size, <strong>including Python’s internal overhead</strong>, which makes pure Python relatively inefficient for data storage and processing. To overcome this, optimized libraries like <strong>NumPy</strong> and <strong>PyTorch</strong> are used. For instance, <strong>NumPy</strong> provides fixed-size types like <code class="language-plaintext highlighter-rouge">int8</code>, <code class="language-plaintext highlighter-rouge">int16, int32</code>, etc. We can check the size of a NumPy object (e.g., <code class="language-plaintext highlighter-rouge">x = np.int16(2)</code>) using <code class="language-plaintext highlighter-rouge">x.nbytes</code>, which gives the actual payload size.</p> <hr> <p><strong>Strings</strong> are represented using <em>bytes</em>, interpreted according to the <strong>character encoding</strong> — the system that maps bits to characters.</p> <p><strong>ASCII</strong> (American Standard Code for Information Interchange) uses <em>one byte per character</em> and defines 256 symbols (128 in the original standard). For example, the string <code class="language-plaintext highlighter-rouge">"Capybara"</code> is be encoded in ASCII as <code class="language-plaintext highlighter-rouge">[67, 97, 112, 121, 98, 97, 114, 97]</code>.</p> <p>When more characters are needed (such as emojis, Chinese ideograms, or mathematical symbols), modern systems use <strong>Unicode</strong>, which assigns a unique code point to every character. To actually store these code points as <em>bytes</em>, <strong>encodings</strong> like <strong>UTF-8</strong>, <strong>UTF-16</strong>, or <strong>UTF-32</strong> are used. In <strong>UTF-8</strong>, each character uses <strong>1 to 4 bytes</strong>, depending on the numerical value of the Unicode code point; and <em>UTF8</em> is backward compatible with ASCII. <em>Version 16.0</em> of the standard defines <em>154,998</em> characters across <em>168</em> scripts.</p> <p>Understanding Unicode and encoding schemes is critical in areas like <strong>Natural Language Processing (NLP)</strong>, where text from multiple languages must be handled efficiently and reliably.</p> <hr> <h2 id="data-types-used-in-deep-learning">Data Types Used in Deep Learning</h2> <p><strong>Deep learning</strong> relies almost entirely on <strong>numerical tensors</strong>. Everything — models, inputs, outputs, intermediate activations — is stored as tensors, and most of them are <strong>floating-point based</strong>.</p> <p>The most common types:</p> <ul> <li> <strong><code class="language-plaintext highlighter-rouge">float32</code></strong>: Single-precision (32-bit floating point) — the default choice for most models.<br> Drawback: large memory usage (both GPU and RAM).</li> <li> <strong><code class="language-plaintext highlighter-rouge">float16</code></strong>: Half-precision (16-bit floating point) — used for faster computation and reduced memory footprint.<br> Challenge: lower dynamic range, can cause instability (overflow and underflow). Especially important for larger models. Used much less nowadays.</li> <li> <strong><code class="language-plaintext highlighter-rouge">bfloat16</code></strong>: Brain Floating Point, designed specifically for deep learning. It addresses the issue with <code class="language-plaintext highlighter-rouge">float16</code> - it keeps the larger dynamic range (the same as <code class="language-plaintext highlighter-rouge">float32</code>), but with reduced fractional precision — better for training stability with less memory. It is <strong>good enough</strong> for forward pass computations.<br> Challenge: for storing optimizer states and parameters, you still need to use <code class="language-plaintext highlighter-rouge">float32</code>.</li> <li> <strong><code class="language-plaintext highlighter-rouge">fp8</code></strong>: 8-bit floating point - a very recent innovation, available on NVIDIA <code class="language-plaintext highlighter-rouge">H100</code> GPUs.<br> Still experimental and not widely adopted.</li> <li> <strong><code class="language-plaintext highlighter-rouge">int8</code></strong>: 8-bit integers — used in quantized models to reduce size and speed up inference.</li> </ul> <p><img src="/assets/img/fp_visual.png" alt="Img.4: Representation of data types in memory" style="width:100%;"></p> <h4 id="floating-point-internals">Floating Point Internals</h4> <p>Floating point formats control the following two things:</p> <ul> <li> <strong>Dynamic range</strong>: how far the binary point shifts — <strong>up to 127 positions</strong> in either direction. We subtract a <strong>bias of 127</strong> (binary 01111111) to allow both positive and negative shifts.</li> <li> <strong>Fractional part</strong>: how finely numbers can be distinguished (handled by the mantissa bits).</li> </ul> <p>For example:</p> <ul> <li> <code class="language-plaintext highlighter-rouge">fp8 E4M3</code> (4 exponent bits, 3 mantissa bits) can represent numbers like <code class="language-plaintext highlighter-rouge">11110</code> and <code class="language-plaintext highlighter-rouge">0.0001111</code> (3+1 meaningful bits).</li> <li> <code class="language-plaintext highlighter-rouge">fp8 E5M2</code> (5 exponent bits, 2 mantissa bits) can represent <code class="language-plaintext highlighter-rouge">111000</code> and <code class="language-plaintext highlighter-rouge">0.0000111</code> (2+1 meaningful bits).</li> </ul> <p>The value of <code class="language-plaintext highlighter-rouge">float32</code> number is calculated as (IEEE 754):</p> \[N = (-1)^{b_{31}} \times 2^{(b_{30}b_{29} \dots b_{23})_2-127} \times (1.b_{22}b_{21} \dots b_0)_2\] <p>We can also write the exponent part in binary directly (more intuitive, if we compare with decimal logic):</p> \[N = (-1)^{b_{31}} \times 2^{(b_{30}b_{29} \dots b_{23})-01111111} \times (1.b_{22}b_{21} \dots b_0)\] <h4 id="quick-back-of-envelope-calculation">Quick Back-of-Envelope Calculation</h4> <p>Suppose we have a tensor <code class="language-plaintext highlighter-rouge">x</code> with shape <code class="language-plaintext highlighter-rouge">(batch_size=32, channels=3, height=224, width=224)</code>, typical for an image recognition model.</p> <p>How much memory would this tensor consume with different types?</p> <ul> <li> <p>Number of elements (<code class="language-plaintext highlighter-rouge">x.numel()</code> in <strong>PyTorch</strong>):<br> <code class="language-plaintext highlighter-rouge">32 × 3 × 224 × 224 = 4,816,896</code></p> </li> <li> <p>Memory usage:</p> <ul> <li> <code class="language-plaintext highlighter-rouge">float32</code> (4 bytes per value):<br> <code class="language-plaintext highlighter-rouge">4,816,896 × 4 = ~ 18.4 MB</code> </li> <li> <code class="language-plaintext highlighter-rouge">float16</code> (2 bytes per value):<br> <code class="language-plaintext highlighter-rouge">4,816,896 × 2 = ~ 9.2 MB</code> </li> <li> <code class="language-plaintext highlighter-rouge">int8</code> (1 byte per value):<br> <code class="language-plaintext highlighter-rouge">4,816,896 × 1 = ~ 4.8 MB</code> </li> </ul> </li> </ul> <p><strong>Notice</strong> Changing the data type immediately halves or quarters the memory footprint.</p> <hr> <p>Choosing the right type has a huge impact on model <strong>speed</strong>, <strong>memory usage</strong>, and <strong>training stability</strong>.</p> <ul> <li>Training with <code class="language-plaintext highlighter-rouge">float32</code> is safe but memory-hungry.</li> <li>Switching to <code class="language-plaintext highlighter-rouge">float16</code>, <code class="language-plaintext highlighter-rouge">fp8</code>, and <code class="language-plaintext highlighter-rouge">bfloat16</code> saves memory and speeds up computation, but introduces <strong>training instability</strong>.</li> <li>Solution: to use <strong>mixed precision</strong> — selectively combining different types to balance memory usage and training stability.</li> </ul> <hr> <h2 id="conclusion">Conclusion</h2> <p>Understanding data types is the foundation of building efficient AI systems.<br> It affects not only how we design models but also how fast and how large they can be.</p> <p>In future posts, I’ll dive deeper into <strong>resource accounting</strong> — covering both <strong>memory</strong> and <strong>FLOPS</strong>. For memory, I’ll go beyond inputs to include gradients, intermediate activations, and other internal components of deep learning models.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="https://medium.com/data-science/live-cnn-training-dashboard-hyperparameters-tuning-6b3382d9e44f?source=rss-7e351a20057c------2" target="_blank" rel="external nofollow noopener">Live CNN Training Dashboard: Hyperparameters Tuning</a> <svg width="1rem" height="1rem" viewbox="0 0 30 30" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="https://medium.com/stanford-cs224w/pyg-implementation-of-edp-gnn-generation-via-score-based-generative-modeling-e45c24d1ce89?source=rss-7e351a20057c------2" target="_blank" rel="external nofollow noopener">PyG Implementation of EDP-GNN: Generation via Score-Based Generative Modeling</a> <svg width="1rem" height="1rem" viewbox="0 0 30 30" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/backward-compute/">Backpropagation: From Intuition to FLOPs</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/compute/">DL Under the Hood: Tensors, Views, and FLOPs</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Aleksandr Timashov. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/img-comparison-slider@8.0.6/dist/index.min.js" integrity="sha256-EXHg3x1K4oIWdyohPeKX2ZS++Wxt/FRPH7Nl01nat1o=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/swiper@11.0.5/swiper-element-bundle.min.js" integrity="sha256-BPrwikijIybg9OQC5SYFFqhBjERYOn97tCureFgYH1E=" crossorigin="anonymous"></script> </body> </html>